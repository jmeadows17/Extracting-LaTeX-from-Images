## Overview

The notebook ```LaTeX Extraction from Images.ipynb``` contains preliminary experiments using VLMs and object detection to extract LaTeX from images of equations. For instance, if we give a model: 

![9](https://github.com/user-attachments/assets/134e2193-450a-4320-8595-8117b9640fe0)

it should return LaTeX similar to:

```\frac{d E_\lambda}{d\lambda} = \bra{\frac{d \Psi_\lambda}{d\lambda}} \hat{H}_\lambda\ket{\Psi_\lambda} + \bra{\Psi_\lambda} \frac{d\hat{H}_\lambda}{d\lambda} \ket{\Psi_\lambda}\\ + \bra{\Psi_\lambda} \hat{H}_\lambda\ket{\frac{d \Psi_\lambda}{d\lambda}}```

We use a small custom dataset of Physics equations (11 image-latex pairs) comprising images manually extracted from [this paper](https://aclanthology.org/2024.findings-emnlp.378.pdf).

## In-context learning

We generate few-shot examples to guide VLM output using ***negative examples from the worst performing model***. The rationale is that by seeing numerous formatting errors over a small number of examples, generated by a VLM, models should learn to correct a considerable number of mistakes.

An example few-shot prompt with 2 in-context examples (i.e. FS_2) is given below:

![3](https://github.com/user-attachments/assets/e3c6ee9f-3c6b-45c4-95f0-b83dc2c7dcd1) 
```
Determine the Correct LaTeX expression of the equation in the image. Below are examples of Incorrect and Correct LaTeX equations: 

Incorrect: \int \left\langle x \mid \Psi \right\rangle \delta ^ { + } \left\langle x ^ { \prime } \mid \delta ^ { - } \left( x - x ^ { \prime } \right) \right\rangle \left\langle x ^ { \prime } \mid \left( x - x ^ { \prime } \right) \Psi \right\rangle \mathrm { d } x ^ { \prime } = \int \left\langle x ^ { \prime } \mid \Psi \right 

Correct: \int \braket{x}{\Psi}^{\dagger}x'\delta(x-x') \braket{x'}{\Psi} dx' \\ = \braket{x}{\Psi}^{\dagger}x \braket{x}{\Psi} 

Incorrect: \dot { \theta } = \{ \theta \} \cdot \dot { \theta } = - 2 \cdot \theta - \theta ^ { \prime } \cdot 1 = 1 

Correct: \phi = \phi_2 - \phi_1 

Give the Correct LaTeX from the image. Correct:
```

## Zero-shot prompt

We use the same [zero-shot prompt](https://huggingface.co/AnyModal/LaTeX-OCR-Llama-3.2-1B) for all models: ```The latex expression of the equation in the image is: ```

## Results

We compare smaller VLMs based on ```LLaMa-3.2-1B/11B``` with ```GPT-4o```. The few-shot results corresponding to ```N``` in-context examples are denoted by ```FS_N``` in the model name (otherwise zero-shot).

![results](https://github.com/user-attachments/assets/3f1bf7c2-6051-4fdf-8450-c7b35fedbd70)

Clearly there is still some distance between smaller open source models and GPT, which is perhaps unsurprising. However, GPT's performance can be improved by including in-context examples generated by small VLMs.




